# 介绍

​																																							“木强则折”  ——老子

​		人类具有很强的学习能力，他们可以从少量的样本中学习出新的理念，并将其应用于未曾遇见的情况之中。因此，基于人类先前经验的基础上，重复利用随着时间而积累下来的概念和抽象化的知识。这样便可以适应从少量新的事例中学习新的技能的模式。我们如何构建这样一个智能系统，使其也拥有人类所拥有的的多功能性与灵活性呢？

​		在我们看来，上述难题的关键是数据的形式。为了阐述这一点，我们可以先看下机器学习中对于处理某一项特定任务的标准范式是怎样的。例如语音识别，文本翻译,图像中的分类任务，玩雅达利游戏以及拧上瓶盖（原文是“playing Atari breakout or screwing on a bottle cap”，我的理解就是打游戏和机械操作任务，强化学习相关）。随后针对这些任务，将训练一个模型或策略，例如使用端到端的方式等，从一个随机开始的状态起始进行模型训练，并解决这个问题。在机器学习领域内部，从头开始进行端到端的方式常常被视作黄金准则，这是因为对于解决问题，机器学习从业人员并不需要所处理的任务所在的特定领域的知识或经验。例如这篇文章Collobert et al. (2011), Yi et al. (2014), and Levine et al. (2016a).然而，从人类如何学习的方式的角度看来，从头开始构造一个只能从单一，独立的任务中解决问题的系统，这绝对是没有任何意义的。这就好像是想让一个婴儿成为一个国际象棋专家，但是在他成为国际象棋专家之前却从来不知道该如何拿起一个棋子。又好比说想让一个婴儿在理解英法两种语言的基本词汇之前学会何英法文互译。这些现有的系统都孤立于非常狭窄的一个场景中，常常为了实用性的考虑而缩小了不足以发展常识的狭隘的经验（的作用？）。（基于上述这样的实现逻辑）如果我们想要一个能够展示人类普遍性智慧的系统，就不得不需要数以百万计的数据点来应对每一个新任务，概念或环境。

​		我们如何构建这样一个系统，它能够可以快速而高效的学习广泛的新理念和新技能？也许可以使用这样的方式，那就是我们可以关注那些已经训练了一个已知系统（也可以理解为模型）的那些数据。例如"MNIST"以及"CIFAR-10"数据集，两者都拥有60000张图片，并被平均的划分为10个类别。虽然这些数据集相对较小，但是都可以推动机器学习研究的进展。值的注意的是，这些数据集组成形式明显不同于人类经验。这些数据集不同于看10个不同对象的额6000个实例（例如6000个叉子，6000个瓶子）人类学习数据的的方式更趋向于一种相反的方式：从6000个不同对象的10个实例中学习。由于能从这一种级别的多样性中学习，所以对于人类能够如此高效的概括，这并不让人感到十分的惊讶。

​		毋庸置疑，数据的分布和性质在泛化中发挥着重要作用，但对各种数据集进行系统训练本身并不会导致适应性。相反，当我们需要尝试着学习新任务的时候，我们需要从多种先验的内容中迁移知识。迁移学习是机器学习领域一个长期的子领域，主要是研究在新数据中学习时，利用先前数据集的能力。可以说，迁移学习最大的现代成功案例之一是对大量先前可用数据进行预训练产生一个预训练模型，然后根据新任务对应的新数据微调预训练模型。这项技术，已经在ImageNet上使用预训练的卷积神经网络中取得了巨大的成功，（除了预训练的CNN之外）包括最近在大语料库上预训练的语言模型。但是，预训练技术目前也只会到此为止，其良好的表现也仅仅局限于少数的几个例子。考虑到人类处理少量数据的能力（即从少量数据中学习的能力），小样本学习更具有挑战性，但是任然有解决的可能。

​		在这篇论文中，我们将考虑一种迁移学习的方法，以优化迁移学习的能力以及快速学习的能力。这类方法明确地培养了学习新概念或学习如何学习的能力。 虽然学习到学习或元学习的概念并不新鲜，深度学习和基于梯度的优化现代技术，伴随着日益增强的计算能力和大型数据集，促使我们以新的方式重新审视这种方法。

​		元学习也可以被视为在先前已知的任务或概念中学习结构，使得该学习的先验可以与少量的新数据组合以进行一般化的推论。从这个角度来看，元学习和分层贝叶斯建模之间存在密切关系，分层贝叶斯建模是一种成功应用于小样本学习的问题的方法。这种元学习的概念在分层贝叶斯模型中学习先验知识将有助于推理学习中的不确定性和发展关于不同方法的直觉。

​		先前的元学习方法大致分为两类：1、通过学习传入数据的方法训练大型黑盒神经网络模型。2、将已知优化程序结构纳入学习器的方法（例如微调么？）。对于前者，好比深度神经网络模型，例如LSTM、神经图灵机、或者其他具有记忆形式或者其他递归形式的模型，都被训练成从传入的数据中学习数据点。这样的模型还需将未标记的新数据作为输入，并得出其输出的标签，或者预测预测可以解决任务的另一个神经网络的权重<font color="#dd0000">*（这一句什么意思？）*</font>。这种方式被wang和Hebert延伸到强化学习领域，通过学习RNN的策略，不在训练的迭代过程中重新设置其隐藏状态，从而使得能够“学习”到先前的迭代过程。这种方式表现力很好并且可以广泛的应用于各种问题。然而，没有任何结构，从头开始学习这些黑盒学习程序可能是困难和低效的。

​		许多先前的工作旨在将结构<font color="#dd0000">*（这里的结构是什么意思？）*</font>纳入元学习过程。尤其，一种有效的小样本学习分类的方式是比较学习度量空间中的示例，例如[孪生神经网络（Siamese networks）](https://zhuanlan.zhihu.com/p/35040994)或者递归模型。这些方式中有一些创造了十分成功的结果，但是很难将他们成功的方式推广到其他问题之中，例如强化学习。这个先前的文献推动了具有黑盒特性的一般性的方法的开发，如后者的递归模型，并且这个过程中伴随着结合结构，如孪生神经网络。此外，这些工作很大程度上都是独立开发的，这导致了彼此之间没有通用的术语甚至没有针对常见问题的陈述。如果我们希望推动这些方法的研究与理解，拥有一些具体的指导性原则以及具体但充分的一般性问题陈述，这将会是十分有帮助的，这篇论文所希望做的便是实现这些方针。

​		对本论文的贡献大致由以下几个部分组成：

- 在第2章节，我们研究了元学习的问题陈述，并给出这些陈述对应的不同的示例。我们的问题定义和符号的内容包含元监督和元强化学习设置。
- 在第3章节，我们定义了一组可测量的元学习算法的性能指标，旨在为那些开发新的元学习算法的人提出一套指导原则。
- 在第4章节，我们提出了我们的核心贡献，这是一种简单而通用的元学习方法，它建立在从预先训练的初始化微调成功的基础上。我们分析了这种不可知模型的元学习算法的理论性质。并且在经验上将它与先前的方法进行比较，包括小样本有监督学习问题和快速强化学习。这项工作的一部分以前发表过在Finn et al. (2017a) and Finn and Levine (2018)。
- 在第5章节，我先不写了，等翻译到第五章节再写。























































# 参考书目



你好

